{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explode_posexplode_example.txt\tmulti_deli_file.txt  wordcount.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Workdcount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = sc.textFile('wordcount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in this chapter we are going to familiarize on how to use the Jupyter notebook with PySpark with the help of word count example. I recommend the user to do follow the steps in this chapter and practice to make themselves familiar with the environment. In our previous chapter, we installed all the required software to start with PySpark, hope you are ready with the setup, if not please follow the steps and install before starting from Install pyspark in jupyter notebook.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_text = in_text.flatMap(lambda x:x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'this',\n",
       " 'chapter',\n",
       " 'we',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'familiarize',\n",
       " 'on',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'the',\n",
       " 'Jupyter',\n",
       " 'notebook',\n",
       " 'with',\n",
       " 'PySpark',\n",
       " 'with',\n",
       " 'the',\n",
       " 'help',\n",
       " 'of',\n",
       " 'word',\n",
       " 'count',\n",
       " 'example.',\n",
       " 'I',\n",
       " 'recommend',\n",
       " 'the',\n",
       " 'user',\n",
       " 'to',\n",
       " 'do',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'steps',\n",
       " 'in',\n",
       " 'this',\n",
       " 'chapter',\n",
       " 'and',\n",
       " 'practice',\n",
       " 'to',\n",
       " 'make',\n",
       " 'themselves',\n",
       " 'familiar',\n",
       " 'with',\n",
       " 'the',\n",
       " 'environment.',\n",
       " 'In',\n",
       " 'our',\n",
       " 'previous',\n",
       " 'chapter,',\n",
       " 'we',\n",
       " 'installed',\n",
       " 'all',\n",
       " 'the',\n",
       " 'required',\n",
       " 'software',\n",
       " 'to',\n",
       " 'start',\n",
       " 'with',\n",
       " 'PySpark,',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'are',\n",
       " 'ready',\n",
       " 'with',\n",
       " 'the',\n",
       " 'setup,',\n",
       " 'if',\n",
       " 'not',\n",
       " 'please',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'steps',\n",
       " 'and',\n",
       " 'install',\n",
       " 'before',\n",
       " 'starting',\n",
       " 'from',\n",
       " 'Install',\n",
       " 'pyspark',\n",
       " 'in',\n",
       " 'jupyter',\n",
       " 'notebook.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_flat_mapped =flat_text.map(lambda x:(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 1),\n",
       " ('this', 1),\n",
       " ('chapter', 1),\n",
       " ('we', 1),\n",
       " ('are', 1),\n",
       " ('going', 1),\n",
       " ('to', 1),\n",
       " ('familiarize', 1),\n",
       " ('on', 1),\n",
       " ('how', 1),\n",
       " ('to', 1),\n",
       " ('use', 1),\n",
       " ('the', 1),\n",
       " ('Jupyter', 1),\n",
       " ('notebook', 1),\n",
       " ('with', 1),\n",
       " ('PySpark', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('help', 1),\n",
       " ('of', 1),\n",
       " ('word', 1),\n",
       " ('count', 1),\n",
       " ('example.', 1),\n",
       " ('I', 1),\n",
       " ('recommend', 1),\n",
       " ('the', 1),\n",
       " ('user', 1),\n",
       " ('to', 1),\n",
       " ('do', 1),\n",
       " ('follow', 1),\n",
       " ('the', 1),\n",
       " ('steps', 1),\n",
       " ('in', 1),\n",
       " ('this', 1),\n",
       " ('chapter', 1),\n",
       " ('and', 1),\n",
       " ('practice', 1),\n",
       " ('to', 1),\n",
       " ('make', 1),\n",
       " ('themselves', 1),\n",
       " ('familiar', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('environment.', 1),\n",
       " ('In', 1),\n",
       " ('our', 1),\n",
       " ('previous', 1),\n",
       " ('chapter,', 1),\n",
       " ('we', 1),\n",
       " ('installed', 1),\n",
       " ('all', 1),\n",
       " ('the', 1),\n",
       " ('required', 1),\n",
       " ('software', 1),\n",
       " ('to', 1),\n",
       " ('start', 1),\n",
       " ('with', 1),\n",
       " ('PySpark,', 1),\n",
       " ('hope', 1),\n",
       " ('you', 1),\n",
       " ('are', 1),\n",
       " ('ready', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('setup,', 1),\n",
       " ('if', 1),\n",
       " ('not', 1),\n",
       " ('please', 1),\n",
       " ('follow', 1),\n",
       " ('the', 1),\n",
       " ('steps', 1),\n",
       " ('and', 1),\n",
       " ('install', 1),\n",
       " ('before', 1),\n",
       " ('starting', 1),\n",
       " ('from', 1),\n",
       " ('Install', 1),\n",
       " ('pyspark', 1),\n",
       " ('in', 1),\n",
       " ('jupyter', 1),\n",
       " ('notebook.', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_flat_mapped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_flat_mapped_reduced = text_flat_mapped.reduceByKey(lambda x,y :x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 3),\n",
       " ('this', 2),\n",
       " ('chapter', 2),\n",
       " ('we', 2),\n",
       " ('are', 2),\n",
       " ('use', 1),\n",
       " ('PySpark', 1),\n",
       " ('help', 1),\n",
       " ('of', 1),\n",
       " ('count', 1),\n",
       " ('example.', 1),\n",
       " ('recommend', 1),\n",
       " ('do', 1),\n",
       " ('steps', 2),\n",
       " ('make', 1),\n",
       " ('themselves', 1),\n",
       " ('chapter,', 1),\n",
       " ('installed', 1),\n",
       " ('start', 1),\n",
       " ('PySpark,', 1),\n",
       " ('ready', 1),\n",
       " ('setup,', 1),\n",
       " ('install', 1),\n",
       " ('before', 1),\n",
       " ('starting', 1),\n",
       " ('Install', 1),\n",
       " ('jupyter', 1),\n",
       " ('notebook.', 1),\n",
       " ('going', 1),\n",
       " ('to', 5),\n",
       " ('familiarize', 1),\n",
       " ('on', 1),\n",
       " ('how', 1),\n",
       " ('the', 8),\n",
       " ('Jupyter', 1),\n",
       " ('notebook', 1),\n",
       " ('with', 5),\n",
       " ('word', 1),\n",
       " ('I', 1),\n",
       " ('user', 1),\n",
       " ('follow', 2),\n",
       " ('and', 2),\n",
       " ('practice', 1),\n",
       " ('familiar', 1),\n",
       " ('environment.', 1),\n",
       " ('In', 1),\n",
       " ('our', 1),\n",
       " ('previous', 1),\n",
       " ('all', 1),\n",
       " ('required', 1),\n",
       " ('software', 1),\n",
       " ('hope', 1),\n",
       " ('you', 1),\n",
       " ('if', 1),\n",
       " ('not', 1),\n",
       " ('please', 1),\n",
       " ('from', 1),\n",
       " ('pyspark', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_flat_mapped_reduced.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
