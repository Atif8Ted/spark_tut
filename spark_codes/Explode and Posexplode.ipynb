{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=Q2UoBmvTV78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](ss.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 288\r\n",
      "-rw-r--r-- 1 atif atif     56 Nov 14 17:19  multi_deli_file.txt\r\n",
      "drwxr-xr-x 2 atif atif   4096 Nov 14 18:09  data2\r\n",
      "drwxr-xr-x 2 atif atif   4096 Nov 14 18:10  data1\r\n",
      "drwxr-xr-x 2 atif atif   4096 Nov 14 18:14  data3\r\n",
      "-rw-r--r-- 1 atif atif   7729 Nov 14 18:22  multi_delimeted_file_handling.ipynb\r\n",
      "-rw-r--r-- 1 atif atif   9716 Nov 14 18:23 'Load Data from multiple directory.ipynb'\r\n",
      "-rw-r--r-- 1 atif atif 249704 Nov 14 18:55  ss.png\r\n",
      "-rw-r--r-- 1 atif atif    793 Nov 14 18:58 'Explode and Posexplode.ipynb'\r\n",
      "-rw-r--r-- 1 atif atif     89 Nov 14 19:02  explode_posexplode_example.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name|Age|Education\r\n",
      "Azar|25|MBA,BE,HSC\r\n",
      "HARI|32|\r\n",
      "KUMAR|35|ME,BE,Diploma\r\n",
      "IMAM|24|B.Tech,HSC\r\n"
     ]
    }
   ],
   "source": [
    "!cat explode_posexplode_example.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('explode_posexplode').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in =spark.read.csv('explode_posexplode_example.txt',sep='|',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+\n",
      "| Name|Age|    Education|\n",
      "+-----+---+-------------+\n",
      "| Azar| 25|   MBA,BE,HSC|\n",
      "| HARI| 32|         null|\n",
      "|KUMAR| 35|ME,BE,Diploma|\n",
      "| IMAM| 24|   B.Tech,HSC|\n",
      "+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode =df_in.withColumn(\"Degrees\",explode(split(\"Education\",\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+-------+\n",
      "| Name|Age|    Education|Degrees|\n",
      "+-----+---+-------------+-------+\n",
      "| Azar| 25|   MBA,BE,HSC|    MBA|\n",
      "| Azar| 25|   MBA,BE,HSC|     BE|\n",
      "| Azar| 25|   MBA,BE,HSC|    HSC|\n",
      "|KUMAR| 35|ME,BE,Diploma|     ME|\n",
      "|KUMAR| 35|ME,BE,Diploma|     BE|\n",
      "|KUMAR| 35|ME,BE,Diploma|Diploma|\n",
      "| IMAM| 24|   B.Tech,HSC| B.Tech|\n",
      "| IMAM| 24|   B.Tech,HSC|    HSC|\n",
      "+-----+---+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### but as you can we have missed `HARI` as it didn't had any entry in Education column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will use explode_out instead of explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode_outer,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode_outer =df_in.withColumn(\"Degrees\",explode_outer(split(\"Education\",\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+-------+\n",
      "| Name|Age|    Education|Degrees|\n",
      "+-----+---+-------------+-------+\n",
      "| Azar| 25|   MBA,BE,HSC|    MBA|\n",
      "| Azar| 25|   MBA,BE,HSC|     BE|\n",
      "| Azar| 25|   MBA,BE,HSC|    HSC|\n",
      "| HARI| 32|         null|   null|\n",
      "|KUMAR| 35|ME,BE,Diploma|     ME|\n",
      "|KUMAR| 35|ME,BE,Diploma|     BE|\n",
      "|KUMAR| 35|ME,BE,Diploma|Diploma|\n",
      "| IMAM| 24|   B.Tech,HSC| B.Tech|\n",
      "| IMAM| 24|   B.Tech,HSC|    HSC|\n",
      "+-----+---+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode_outer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need positional index of degrees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, we will need posexplode , but posexplode doesn't combine with withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import posexplode_outer,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "The number of aliases supplied in the AS clause does not match the number of columns output by the UDTF expected 2 aliases but got Degrees ;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-21e30a6e09f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_pos_explode_outer\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Degrees\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposexplode_outer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Education\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/test/venv/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \"\"\"\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/test/venv/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/test/venv/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/test/venv/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: The number of aliases supplied in the AS clause does not match the number of columns output by the UDTF expected 2 aliases but got Degrees ;"
     ]
    }
   ],
   "source": [
    "df_pos_explode_outer =df_in.withColumn(\"Degrees\",posexplode_outer(split(\"Education\",\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_explode_outer =df_in.select(\"*\",posexplode_outer(split(\"Education\",\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+----+-------+\n",
      "| Name|Age|    Education| pos|    col|\n",
      "+-----+---+-------------+----+-------+\n",
      "| Azar| 25|   MBA,BE,HSC|   0|    MBA|\n",
      "| Azar| 25|   MBA,BE,HSC|   1|     BE|\n",
      "| Azar| 25|   MBA,BE,HSC|   2|    HSC|\n",
      "| HARI| 32|         null|null|   null|\n",
      "|KUMAR| 35|ME,BE,Diploma|   0|     ME|\n",
      "|KUMAR| 35|ME,BE,Diploma|   1|     BE|\n",
      "|KUMAR| 35|ME,BE,Diploma|   2|Diploma|\n",
      "| IMAM| 24|   B.Tech,HSC|   0| B.Tech|\n",
      "| IMAM| 24|   B.Tech,HSC|   1|    HSC|\n",
      "+-----+---+-------------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pos_explode_outer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets rename column 'col' and pos to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_explode_outer =df_pos_explode_outer.withColumnRenamed(\"col\",'Qualification').\\\n",
    "withColumnRenamed(\"pos\",\"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------+-----+-------------+\n",
      "| Name|Age|    Education|Index|Qualification|\n",
      "+-----+---+-------------+-----+-------------+\n",
      "| Azar| 25|   MBA,BE,HSC|    0|          MBA|\n",
      "| Azar| 25|   MBA,BE,HSC|    1|           BE|\n",
      "| Azar| 25|   MBA,BE,HSC|    2|          HSC|\n",
      "| HARI| 32|         null| null|         null|\n",
      "|KUMAR| 35|ME,BE,Diploma|    0|           ME|\n",
      "|KUMAR| 35|ME,BE,Diploma|    1|           BE|\n",
      "|KUMAR| 35|ME,BE,Diploma|    2|      Diploma|\n",
      "| IMAM| 24|   B.Tech,HSC|    0|       B.Tech|\n",
      "| IMAM| 24|   B.Tech,HSC|    1|          HSC|\n",
      "+-----+---+-------------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pos_explode_outer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets drop the column Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_explode_outer = df_pos_explode_outer.drop(\"Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+-------------+\n",
      "| Name|Age|Index|Qualification|\n",
      "+-----+---+-----+-------------+\n",
      "| Azar| 25|    0|          MBA|\n",
      "| Azar| 25|    1|           BE|\n",
      "| Azar| 25|    2|          HSC|\n",
      "| HARI| 32| null|         null|\n",
      "|KUMAR| 35|    0|           ME|\n",
      "|KUMAR| 35|    1|           BE|\n",
      "|KUMAR| 35|    2|      Diploma|\n",
      "| IMAM| 24|    0|       B.Tech|\n",
      "| IMAM| 24|    1|          HSC|\n",
      "+-----+---+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pos_explode_outer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
