{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Broadcasting Example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"uspopulation.csv\",sep='|',header=True)"
   ]
  },
  {
   "source": [
    "df.show(5,truncate =0)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-----------+----------+-------------+-----------+------------------+\n|2019_rank|City       |State_Code|2019_estimate|2010_Census|Change            |\n+---------+-----------+----------+-------------+-----------+------------------+\n|1        |New York[d]|NY        |8336817      |8175133    |0.0198            |\n|2        |Los Angeles|CA        |3979576      |3792621    |0.0493            |\n|3        |Chicago    |IL        |2693976      |2695598    |−0.06%            |\n|4        |Houston[3] |TX        |2320268      |2100263    |0.1048            |\n|5        |Phoenix    |AZ        |1680992      |1445632    |0.1628            |\n+---------+-----------+----------+-------------+-----------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### Lets create lookup dictionary , which will keep record of abbreviation of State_code , \n",
    "### and we will broadcast it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup =dict({\n",
    "\"TX\":\"Texas\",\n",
    "\"NY\":\"New York\",\n",
    "\"OH\":\"OHIO\",\n",
    "\"CA\" :\"California\",\n",
    "\"IL\":\"Illionis\",\n",
    "\"CO\":\"Colorado\",\n",
    "\"AZ\":\"ARIZONA\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'TX': 'Texas',\n",
       " 'NY': 'New York',\n",
       " 'OH': 'OHIO',\n",
       " 'CA': 'California',\n",
       " 'IL': 'Illionis',\n",
       " 'CO': 'Colorado',\n",
       " 'AZ': 'ARIZONA'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "broa_cast = sc.broadcast(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Texas'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "broa_cast.value[\"TX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,col\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadval(col_name):\n",
    "    return broa_cast.value[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_full_name = udf(broadval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+-----------+----------+-------------+-----------+------------------+----------+\n|2019_rank|City       |State_Code|2019_estimate|2010_Census|Change            |state     |\n+---------+-----------+----------+-------------+-----------+------------------+----------+\n|1        |New York[d]|NY        |8336817      |8175133    |0.0198            |New York  |\n|2        |Los Angeles|CA        |3979576      |3792621    |0.0493            |California|\n|3        |Chicago    |IL        |2693976      |2695598    |−0.06%            |Illionis  |\n|4        |Houston[3] |TX        |2320268      |2100263    |0.1048            |Texas     |\n|5        |Phoenix    |AZ        |1680992      |1445632    |0.1628            |ARIZONA   |\n|6        |San Antonio|TX        |1547253      |1327407    |0.1656            |Texas     |\n|7        |San Diego  |CA        |1423851      |1307402    |0.0891            |California|\n|8        |Dallas     |TX        |1343573      |1197816    |0.1217            |Texas     |\n|9        |San Jose   |CA        |1021795      |945942     |0.0802            |California|\n|10       |Austin     |TX        |978908       |790390     |0.2385            |Texas     |\n+---------+-----------+----------+-------------+-----------+------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"state\",get_full_name(\"State_Code\")).show(10,truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "== Physical Plan ==\n*(1) Project [2019_rank#16, City#17, State_Code#18, 2019_estimate#19, 2010_Census#20, Change#21, pythonUDF0#269 AS state#261]\n+- BatchEvalPython [broadval(State_Code#18)], [pythonUDF0#269]\n   +- FileScan csv [2019_rank#16,City#17,State_Code#18,2019_estimate#19,2010_Census#20,Change#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/atif/PycharmProjects/test/spark_codes/spark_learn/uspopulation.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<2019_rank:string,City:string,State_Code:string,2019_estimate:string,2010_Census:string,Cha...\n\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"state\",get_full_name(\"State_Code\")).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}